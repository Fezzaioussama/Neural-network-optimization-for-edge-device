{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Define a simple CNN teacher model (larger model)\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.fc = nn.Linear(32 * 32 * 32, 10)  # Example: 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a simpler CNN student model\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.fc = nn.Linear(16 * 32 * 32, 10)  # Example: 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NZrshHUe9UNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset as an example\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPu9ypdb9YiC",
        "outputId": "3dfd00ec-68fe-4e28-c0c3-567343a4b0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def custom_kl_div_loss(student_logits, teacher_logits, reduction='batchmean'):\n",
        "    # Apply softmax to the logits\n",
        "    student_probs = F.softmax(student_logits, dim=1)\n",
        "    teacher_probs = F.softmax(teacher_logits, dim=1)\n",
        "\n",
        "    # Compute KL Divergence\n",
        "    kl_div = torch.sum(teacher_probs * (torch.log(teacher_probs) - torch.log(student_probs)), dim=1)\n",
        "\n",
        "    if reduction == 'none':\n",
        "        return kl_div\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(kl_div)\n",
        "    elif reduction == 'mean':\n",
        "        return torch.mean(kl_div)\n",
        "    elif reduction == 'batchmean':\n",
        "        return torch.mean(kl_div)"
      ],
      "metadata": {
        "id": "qSgRJKOp9--R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize teacher and student models\n",
        "teacher_model = TeacherModel()\n",
        "student_model = StudentModel()\n",
        "\n",
        "# Define loss functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#distillation_criterion = nn.KLDivLoss()\n",
        "# Define optimizer for the student model\n",
        "optimizer1 = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(student_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "5564EG5T9eta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for Teacher model model\n",
        "num_epochs = 1\n",
        "alpha = 0.7\n",
        "T=0.5\n",
        "for epoch in range(num_epochs):\n",
        "    teacher_model.train()\n",
        "    for inputs, labels in train_dataset:\n",
        "        optimizer1.zero_grad()\n",
        "\n",
        "        # Forward pass through the models\n",
        "        teacher_logits = teacher_model(inputs.unsqueeze(0))\n",
        "\n",
        "        labels = torch.tensor([labels])\n",
        "        ce_loss = criterion(teacher_logits, labels)\n",
        "        total_loss = ce_loss\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer1.step()"
      ],
      "metadata": {
        "id": "_y3_jK81LAPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for student model\n",
        "num_epochs = 1\n",
        "alpha = 0.7\n",
        "T=0.5\n",
        "for epoch in range(num_epochs):\n",
        "    student_model.train()\n",
        "    for inputs, labels in train_dataset:\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        # Forward pass through the models\n",
        "        teacher_logits = teacher_model(inputs.unsqueeze(0))\n",
        "        student_logits = student_model(inputs.unsqueeze(0))\n",
        "        labels = torch.tensor([labels])\n",
        "        ce_loss = criterion(student_logits, labels)\n",
        "        distillation_loss = custom_kl_div_loss(student_logits/T,teacher_logits/T)\n",
        "        total_loss = ce_loss + (alpha * distillation_loss)\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer2.step()"
      ],
      "metadata": {
        "id": "y013UbcI9j1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop\n",
        "student_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dataset:\n",
        "        student_logits = student_model(inputs.unsqueeze(0))\n",
        "        _, predicted = torch.max(student_logits, 1)\n",
        "        total += 1\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Save the trained student model for later use\n",
        "torch.save(student_model.state_dict(), 'student_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htnBDksf9vb7",
        "outputId": "87928104-53e6-489f-acec-f4e5ca682c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 10.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3NLh1-vxNSL",
        "outputId": "5e9ec462-306d-4adf-e12c-20f284ef7def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 10.00%\n"
          ]
        }
      ],
      "source": [
        "# Testing loop\n",
        "student_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dataset:\n",
        "        student_logits = student_model(inputs.unsqueeze(0))\n",
        "        _, predicted = torch.max(student_logits, 1)\n",
        "        total += 1\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in train_dataset:\n",
        "    inputs\n"
      ],
      "metadata": {
        "id": "s00cab5iSBpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.size()\n",
        "x=student_model(inputs.unsqueeze(0))\n",
        "labels\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cLJv-VSTE8_",
        "outputId": "123444d0-a3bf-4419-872c-c44fc620d2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1038, -0.2898, -0.2397,  0.3103,  0.0420, -0.3298, -0.1199,  0.0911,\n",
              "         -0.2800, -0.0858]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPHy5u6hTi6r",
        "outputId": "a0a0e453-7a85-4a4a-d251-6f6c3255b2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = torch.max(x, 1)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAtyymkxTppk",
        "outputId": "f5988a92-9355-4697-fd95-6a699a8e8a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([0.3103], grad_fn=<MaxBackward0>),\n",
              "indices=tensor([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge distillation from ResNet18"
      ],
      "metadata": {
        "id": "iMQYOthMNKhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset as an example\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "dblhE8luRjPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# child model\n",
        "student_model = StudentModel()\n",
        "# Define loss functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#distillation_criterion = nn.KLDivLoss()\n",
        "# Define optimizer for the student model\n",
        "optimizer1 = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "optimizer2 = optim.Adam(student_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "n7KxllVLRtCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pre-trained ResNet-18 model\n",
        "modelteacher = models.resnet18(pretrained=True)\n",
        "modelteacher.eval()\n",
        "# child model\n",
        "class SimpleStudModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleStudModel, self).__init__()\n",
        "        # Define a simple architecture with fewer parameters\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define CIFAR-specific transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "# Instantiate the student model with the number of classes in your task\n",
        "num_classes = 10  # You may adjust this based on your specific task\n",
        "student_model = SimpleStudModel(num_classes)\n",
        "\n",
        "# Function to perform inference on an image\n",
        "def inference(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    with torch.no_grad():\n",
        "        output = modelteacher(image_tensor)\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    return probabilities\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/Sans titre.jpeg\"  # Replace with the actual image path\n",
        "\n",
        "result = inference(image_path)\n",
        "class_idx = torch.argmax(result).item()\n",
        "\n",
        "# You may need to download the CIFAR-10 class labels from https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "# and load them here to interpret the output class index.\n",
        "\n",
        "print(f\"Predicted class index: {class_idx}\")\n",
        "print(len(result))\n",
        "\n",
        "# Training loop for student model\n",
        "num_epochs = 1\n",
        "alpha = 0.7\n",
        "T=0.5\n",
        "for epoch in range(num_epochs):\n",
        "    student_model.train()\n",
        "    for inputs, labels in train_dataset:\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        # Forward pass through the models\n",
        "        teacher_logits = modelteacher(inputs.unsqueeze(0))\n",
        "        student_logits = student_model(inputs.unsqueeze(0))\n",
        "        labels = torch.tensor([labels])\n",
        "        ce_loss = criterion(student_logits, labels)\n",
        "        distillation_loss = custom_kl_div_loss(student_logits/T,teacher_logits/T)\n",
        "        total_loss = ce_loss + (alpha * distillation_loss)\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer2.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwSKmRLBNO2f",
        "outputId": "4b6dc874-0bbe-4441-bf60-bd00c2266f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 257\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1lke1BooQom-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}