{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3M0iAsbrzkx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_steps=4, device=''):\n",
        "        super(Agent, self).__init__()\n",
        "\n",
        "        # Could add an embedding layer\n",
        "        # embedding_size = 100\n",
        "        # self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        # dropout layer\n",
        "        #self.drop = nn.Dropout(dropout)\n",
        "        self.DEVICE = device\n",
        "        self.num_filter_option = 3\n",
        "        self.filter_size_option = 3\n",
        "\n",
        "        self.lstm1 = nn.LSTMCell(input_size, hidden_size)\n",
        "        # May be could just use different decoder if these two numbers are the same, not sure\n",
        "        self.decoder = nn.Linear(hidden_size, self.num_filter_option)\n",
        "        #self.decoder2 = nn.Linear(hidden_size, self.filter_size_option)\n",
        "\n",
        "        # num_steps = max_layer * 2 # two conv layer * 2 h-parameters (kernel size and number of kernels)\n",
        "        self.num_steps = num_steps\n",
        "        self.nhid = hidden_size\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def forward(self, input):\n",
        "        outputs = []\n",
        "        h_t, c_t = self.hidden\n",
        "\n",
        "        for i in range(self.num_steps):\n",
        "            # input_data = self.embedding(step_data)\n",
        "            h_t, c_t = self.lstm1(input, (h_t, c_t))\n",
        "            # Add drop out\n",
        "            # h_t = self.drop(h_t)\n",
        "            output = self.decoder(h_t)\n",
        "            input = output\n",
        "            outputs += [output]\n",
        "\n",
        "        outputs = torch.stack(outputs).squeeze(1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def init_hidden(self):\n",
        "        h_t = torch.zeros(1, self.nhid, dtype=torch.float, device=self.DEVICE)\n",
        "        c_t = torch.zeros(1, self.nhid, dtype=torch.float, device=self.DEVICE)\n",
        "\n",
        "        return (h_t, c_t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generic model design\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class NASModel(nn.Module):\n",
        "    def __init__(self, actions):\n",
        "        super(NASModel, self).__init__()\n",
        "        # unpack the actions from the list\n",
        "        self.kernel_1, self.filters_1, self.kernel_2, self.filters_2 = actions.tolist()\n",
        "        # input size 3 * 32 * 32, use default stride=1 and padding=0\n",
        "        # w and h could be calculated using the below equation\n",
        "        # w = (w - filter_size + 2*p)/stride + 1 = w - filter_size + 1\n",
        "        # thus if use 2*2 max pooling, (w - filter_size + 1) % 2 = 0\n",
        "        # filter size could be in [3, 5, 7], also, we limit filter numbers to be [8, 16, 32]\n",
        "        self.conv1 = nn.Conv2d(3, self.filters_1, self.kernel_1)\n",
        "        # input filters_1 * (33 - kernel_1) * (33 - kernel_1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # input filters_1 * ((33 - kernel_1) / 2) * ((33 - kernel_1) / 2)\n",
        "        self.conv2 = nn.Conv2d(self.filters_1, self.filters_2, self.kernel_2)\n",
        "        # input filters_2 * ((33 - kernel_1) / 2 - kernel_2 + 1) * ((33 - kernel_1) / 2 - kernel_2 + 1)\n",
        "\n",
        "\n",
        "        self.tmp = int(self.filters_2 * ((33 - self.kernel_1) / 2 - self.kernel_2 + 1) *\n",
        "                             ((33 - self.kernel_1) / 2 - self.kernel_2 + 1))\n",
        "        self.fc1 = nn.Linear(self.tmp, 84)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.tmp)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "#\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "#         self.fc2 = nn.Linear(120, 84)\n",
        "#         self.fc3 = nn.Linear(84, 10)\n",
        "#\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\n",
        "#         x = x.view(-1, 16 * 5 * 5)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "2mYjZo31sBix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.nn.functional import one_hot, log_softmax, softmax, normalize\n",
        "from torch.distributions import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#from controller import  Agent\n",
        "from collections import deque\n",
        "#from model import  NASModel\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "class PolicyGradient:\n",
        "    def __init__(self, config, train_set, test_set, use_cuda=False):\n",
        "\n",
        "        self.NUM_EPOCHS = config.NUM_EPOCHS\n",
        "        self.ALPHA = config.ALPHA\n",
        "        self.BATCH_SIZE = config.BATCH_SIZE # number of models to generate for each action\n",
        "        self.HIDDEN_SIZE = config.HIDDEN_SIZE\n",
        "        self.BETA = config.BETA\n",
        "        self.GAMMA = config.GAMMA\n",
        "        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() and use_cuda else 'cpu')\n",
        "        self.INPUT_SIZE = config.INPUT_SIZE\n",
        "        self.NUM_STEPS = config.NUM_STEPS\n",
        "        self.ACTION_SPACE = config.ACTION_SPACE\n",
        "\n",
        "        self.train = train_set\n",
        "        self.test = test_set\n",
        "\n",
        "        # instantiate the tensorboard writer\n",
        "        self.writer = SummaryWriter(comment=f'_PG_CP_Gamma={self.GAMMA},'\n",
        "                                            f'LR={self.ALPHA},'\n",
        "                                            f'BS={self.BATCH_SIZE},'\n",
        "                                            f'NH={self.HIDDEN_SIZE},'\n",
        "                                            f'BETA={self.BETA}')\n",
        "\n",
        "        # the agent driven by a neural network architecture\n",
        "        if use_cuda:\n",
        "            self.agent = Agent(self.INPUT_SIZE, self.HIDDEN_SIZE, self.NUM_STEPS, device=self.DEVICE).cuda()\n",
        "        else:\n",
        "            self.agent = Agent(self.INPUT_SIZE, self.HIDDEN_SIZE, self.NUM_STEPS, device=self.DEVICE)\n",
        "        self.adam = optim.Adam(params=self.agent.parameters(), lr=self.ALPHA)\n",
        "        self.total_rewards = deque([], maxlen=100)\n",
        "\n",
        "\n",
        "    def solve_environment(self):\n",
        "        \"\"\"\n",
        "            The main interface for the Policy Gradient solver\n",
        "        \"\"\"\n",
        "        # init the episode and the epoch\n",
        "        epoch = 0\n",
        "\n",
        "        while epoch < self.NUM_EPOCHS:\n",
        "            # init the epoch arrays\n",
        "            # used for entropy calculation\n",
        "            epoch_logits = torch.empty(size=(0, self.ACTION_SPACE), device=self.DEVICE)\n",
        "            epoch_weighted_log_probs = torch.empty(size=(0,), dtype=torch.float, device=self.DEVICE)\n",
        "\n",
        "            # Sample BATCH_SIZE models and do average\n",
        "            for i in range(self.BATCH_SIZE):\n",
        "                # play an episode of the environment\n",
        "                (episode_weighted_log_prob_trajectory,\n",
        "                 episode_logits,\n",
        "                 sum_of_episode_rewards) = self.play_episode()\n",
        "\n",
        "                # after each episode append the sum of total rewards to the deque\n",
        "                self.total_rewards.append(sum_of_episode_rewards)\n",
        "\n",
        "                # append the weighted log-probabilities of actions\n",
        "                epoch_weighted_log_probs = torch.cat((epoch_weighted_log_probs, episode_weighted_log_prob_trajectory),\n",
        "                                                     dim=0)\n",
        "                # append the logits - needed for the entropy bonus calculation\n",
        "                epoch_logits = torch.cat((epoch_logits, episode_logits), dim=0)\n",
        "\n",
        "            # calculate the loss\n",
        "            loss, entropy = self.calculate_loss(epoch_logits=epoch_logits,\n",
        "                                                weighted_log_probs=epoch_weighted_log_probs)\n",
        "\n",
        "            # zero the gradient\n",
        "            self.adam.zero_grad()\n",
        "\n",
        "            # backprop\n",
        "            loss.backward()\n",
        "\n",
        "            # update the parameters\n",
        "            self.adam.step()\n",
        "\n",
        "            # feedback\n",
        "            print(\"\\r\", f\"Epoch: {epoch}, Avg Return per Epoch: {np.mean(self.total_rewards):.3f}\",\n",
        "                  end=\"\",\n",
        "                  flush=True)\n",
        "\n",
        "            self.writer.add_scalar(tag='Average Return over 100 episodes',\n",
        "                                   scalar_value=np.mean(self.total_rewards),\n",
        "                                   global_step=epoch)\n",
        "\n",
        "            self.writer.add_scalar(tag='Entropy',\n",
        "                                   scalar_value=entropy,\n",
        "                                   global_step=epoch)\n",
        "            # check if solved\n",
        "            # if np.mean(self.total_rewards) > 200:\n",
        "            #     print('\\nSolved!')\n",
        "            #     break\n",
        "            epoch += 1\n",
        "        # close the writer\n",
        "        self.writer.close()\n",
        "\n",
        "    def play_episode(self):\n",
        "        \"\"\"\n",
        "            Plays an episode of the environment.\n",
        "            episode: the episode counter\n",
        "            Returns:\n",
        "                sum_weighted_log_probs: the sum of the log-prob of an action multiplied by the reward-to-go from that state\n",
        "                episode_logits: the logits of every step of the episode - needed to compute entropy for entropy bonus\n",
        "                finished_rendering_this_epoch: pass-through rendering flag\n",
        "                sum_of_rewards: sum of the rewards for the episode - needed for the average over 200 episode statistic\n",
        "        \"\"\"\n",
        "        # Init state\n",
        "        init_state = [[3, 8, 16]]\n",
        "\n",
        "        # get the action logits from the agent - (preferences)\n",
        "        episode_logits = self.agent(torch.tensor(init_state).float().to(self.DEVICE))\n",
        "\n",
        "        # sample an action according to the action distribution\n",
        "        action_index = Categorical(logits=episode_logits).sample().unsqueeze(1)\n",
        "\n",
        "        mask = one_hot(action_index, num_classes=self.ACTION_SPACE)\n",
        "\n",
        "        episode_log_probs = torch.sum(mask.float() * log_softmax(episode_logits, dim=1), dim=1)\n",
        "\n",
        "        # append the action to the episode action list to obtain the trajectory\n",
        "        # we need to store the actions and logits so we could calculate the gradient of the performance\n",
        "        #episode_actions = torch.cat((episode_actions, action_index), dim=0)\n",
        "\n",
        "        # Get action actions\n",
        "        action_space = torch.tensor([[3, 5, 7], [8, 16, 32], [3, 5, 7], [8, 16, 32]], device=self.DEVICE)\n",
        "        action = torch.gather(action_space, 1, action_index).squeeze(1)\n",
        "        # generate a submodel given predicted actions\n",
        "        net = NASModel(action)\n",
        "        print(net)\n",
        "        #net = Net()\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "        for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.train, 0):\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                inputs, labels = data\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 2000))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished Training')\n",
        "\n",
        "        # load best performance epoch in this training session\n",
        "        # model.load_weights('weights/temp_network.h5')\n",
        "\n",
        "        # evaluate the model\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in self.test:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print('Accuracy of the network on the 10000 test images: {}'.format(acc))\n",
        "        torch.save(net, 'child_model.pth')\n",
        "\n",
        "        # compute the reward\n",
        "        reward = acc\n",
        "\n",
        "        episode_weighted_log_probs = episode_log_probs * reward\n",
        "        sum_weighted_log_probs = torch.sum(episode_weighted_log_probs).unsqueeze(dim=0)\n",
        "\n",
        "        return  sum_weighted_log_probs, episode_logits, reward\n",
        "\n",
        "    def calculate_loss(self, epoch_logits: torch.Tensor, weighted_log_probs: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
        "        \"\"\"\n",
        "            Calculates the policy \"loss\" and the entropy bonus\n",
        "            Args:\n",
        "                epoch_logits: logits of the policy network we have collected over the epoch\n",
        "                weighted_log_probs: loP * W of the actions taken\n",
        "            Returns:\n",
        "                policy loss + the entropy bonus\n",
        "                entropy: needed for logging\n",
        "        \"\"\"\n",
        "        policy_loss = -1 * torch.mean(weighted_log_probs)\n",
        "\n",
        "        # add the entropy bonus\n",
        "        p = softmax(epoch_logits, dim=1)\n",
        "        log_p = log_softmax(epoch_logits, dim=1)\n",
        "        entropy = -1 * torch.mean(torch.sum(p * log_p, dim=1), dim=0)\n",
        "        entropy_bonus = -1 * self.BETA * entropy\n",
        "\n",
        "        return policy_loss + entropy_bonus, entropy"
      ],
      "metadata": {
        "id": "GxQn7ClpsG8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "#from policy_gradient import PolicyGradient\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_cuda', help='use GPU')\n",
        "\n",
        "\n",
        "class Params:\n",
        "    NUM_EPOCHS = 2\n",
        "    ALPHA = 5e-3        # learning rate\n",
        "    BATCH_SIZE = 3     # how many episodes we want to pack into an epoch\n",
        "    HIDDEN_SIZE = 64    # number of hidden nodes we have in our dnn\n",
        "    BETA = 0.1          # the entropy bonus multiplier\n",
        "    INPUT_SIZE = 3\n",
        "    ACTION_SPACE = 3\n",
        "    NUM_STEPS = 4\n",
        "    GAMMA = 0.99\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Use sys.argv[1:] to exclude the first element (script name) and Jupyter-specific arguments\n",
        "    # args = parser.parse_args(sys.argv[1:])\n",
        "\n",
        "    # use_cuda = args.use_cuda\n",
        "    use_cuda = True\n",
        "    # args = parser.parse_args()\n",
        "    # use_cuda = args.use_cuda\n",
        "    # use_cuda = True\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "    policy_gradient = PolicyGradient(config=Params, train_set=trainloader, test_set=testloader, use_cuda=use_cuda)\n",
        "    policy_gradient.solve_environment()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPWoQDX5vYEG",
        "outputId": "e5f4ded4-f270-48a1-ede3-d46311113918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=3200, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 1.901\n",
            "[1,  4000] loss: 1.612\n",
            "[1,  6000] loss: 1.465\n",
            "[1,  8000] loss: 1.404\n",
            "[1, 10000] loss: 1.348\n",
            "[1, 12000] loss: 1.314\n",
            "[2,  2000] loss: 1.219\n",
            "[2,  4000] loss: 1.183\n",
            "[2,  6000] loss: 1.173\n",
            "[2,  8000] loss: 1.135\n",
            "[2, 10000] loss: 1.109\n",
            "[2, 12000] loss: 1.103\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 58.89\n",
            "NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1936, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 1.963\n",
            "[1,  4000] loss: 1.607\n",
            "[1,  6000] loss: 1.474\n",
            "[1,  8000] loss: 1.378\n",
            "[1, 10000] loss: 1.336\n",
            "[1, 12000] loss: 1.280\n",
            "[2,  2000] loss: 1.209\n",
            "[2,  4000] loss: 1.204\n",
            "[2,  6000] loss: 1.172\n",
            "[2,  8000] loss: 1.163\n",
            "[2, 10000] loss: 1.152\n",
            "[2, 12000] loss: 1.138\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 60.22\n",
            "NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=648, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 2.025\n",
            "[1,  4000] loss: 1.690\n",
            "[1,  6000] loss: 1.583\n",
            "[1,  8000] loss: 1.530\n",
            "[1, 10000] loss: 1.496\n",
            "[1, 12000] loss: 1.454\n",
            "[2,  2000] loss: 1.383\n",
            "[2,  4000] loss: 1.376\n",
            "[2,  6000] loss: 1.362\n",
            "[2,  8000] loss: 1.338\n",
            "[2, 10000] loss: 1.340\n",
            "[2, 12000] loss: 1.307\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 52.6\n",
            " Epoch: 0, Avg Return per Epoch: 57.237NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1296, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 1.983\n",
            "[1,  4000] loss: 1.660\n",
            "[1,  6000] loss: 1.548\n",
            "[1,  8000] loss: 1.484\n",
            "[1, 10000] loss: 1.439\n",
            "[1, 12000] loss: 1.409\n",
            "[2,  2000] loss: 1.313\n",
            "[2,  4000] loss: 1.326\n",
            "[2,  6000] loss: 1.310\n",
            "[2,  8000] loss: 1.252\n",
            "[2, 10000] loss: 1.246\n",
            "[2, 12000] loss: 1.236\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 56.85\n",
            "NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=1600, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 1.945\n",
            "[1,  4000] loss: 1.632\n",
            "[1,  6000] loss: 1.496\n",
            "[1,  8000] loss: 1.441\n",
            "[1, 10000] loss: 1.387\n",
            "[1, 12000] loss: 1.314\n",
            "[2,  2000] loss: 1.253\n",
            "[2,  4000] loss: 1.197\n",
            "[2,  6000] loss: 1.196\n",
            "[2,  8000] loss: 1.191\n",
            "[2, 10000] loss: 1.143\n",
            "[2, 12000] loss: 1.170\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 59.75\n",
            "NASModel(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=2704, out_features=84, bias=True)\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1,  2000] loss: 1.992\n",
            "[1,  4000] loss: 1.632\n",
            "[1,  6000] loss: 1.466\n",
            "[1,  8000] loss: 1.386\n",
            "[1, 10000] loss: 1.333\n",
            "[1, 12000] loss: 1.268\n",
            "[2,  2000] loss: 1.188\n",
            "[2,  4000] loss: 1.198\n",
            "[2,  6000] loss: 1.151\n",
            "[2,  8000] loss: 1.141\n",
            "[2, 10000] loss: 1.145\n",
            "[2, 12000] loss: 1.108\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 60.14\n",
            " Epoch: 1, Avg Return per Epoch: 58.075"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = torch.load('child_model.pth')\n",
        "loaded_model = loaded_model.to(device)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        loaded_model.eval()\n",
        "\n",
        "        # Move images to the same device as the model\n",
        "        images = images.to(device)  # device is the device your model is on\n",
        "\n",
        "        predictions = loaded_model(images)\n",
        "        print(predictions)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i__xbaoBwlVQ",
        "outputId": "4ec845be-65ab-448c-8c03-60fa185d9ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "tensor([[ 0.5383, -1.9863,  1.7260,  2.2973, -0.1701,  2.8148,  0.6227, -0.5442,\n",
            "         -0.8852, -1.9654],\n",
            "        [ 5.0698,  8.5521, -3.7695, -2.3170, -3.6925, -5.2821, -7.5790, -5.2462,\n",
            "          9.7848,  4.4661],\n",
            "        [ 2.7481,  3.5586, -1.7064, -1.4353, -1.6955, -2.3632, -3.9211, -2.2712,\n",
            "          4.5197,  2.3213],\n",
            "        [ 4.4624,  1.9231, -0.3616, -0.3905, -0.7897, -3.1313, -2.9989, -3.7576,\n",
            "          4.6670,  0.8637]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "#from policy_gradient import PolicyGradient\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--use_cuda', help='use GPU')\n",
        "\n",
        "\n",
        "class Params:\n",
        "    NUM_EPOCHS = 5\n",
        "    ALPHA = 5e-3        # learning rate\n",
        "    BATCH_SIZE = 3     # how many episodes we want to pack into an epoch\n",
        "    HIDDEN_SIZE = 64    # number of hidden nodes we have in our dnn\n",
        "    BETA = 0.1          # the entropy bonus multiplier\n",
        "    INPUT_SIZE = 3\n",
        "    ACTION_SPACE = 3\n",
        "    NUM_STEPS = 4\n",
        "    GAMMA = 0.99\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Use sys.argv[1:] to exclude the first element (script name) and Jupyter-specific arguments\n",
        "    # args = parser.parse_args(sys.argv[1:])\n",
        "\n",
        "    # use_cuda = args.use_cuda\n",
        "    use_cuda = True\n",
        "    # args = parser.parse_args()\n",
        "    # use_cuda = args.use_cuda\n",
        "    # use_cuda = True\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "    policy_gradient = PolicyGradient(config=Params, train_set=trainloader, test_set=testloader, use_cuda=use_cuda)\n",
        "    policy_gradient.solve_environment()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CCusNdPsTrC",
        "outputId": "b5d6ed85-2de2-4dfe-922b-5b91bc24acb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13152239.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 1.950\n",
            "[1,  4000] loss: 1.612\n",
            "[1,  6000] loss: 1.505\n",
            "[1,  8000] loss: 1.405\n",
            "[1, 10000] loss: 1.352\n",
            "[1, 12000] loss: 1.300\n",
            "[2,  2000] loss: 1.230\n",
            "[2,  4000] loss: 1.179\n",
            "[2,  6000] loss: 1.149\n",
            "[2,  8000] loss: 1.121\n",
            "[2, 10000] loss: 1.094\n",
            "[2, 12000] loss: 1.093\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 62.7\n",
            "[1,  2000] loss: 1.935\n",
            "[1,  4000] loss: 1.553\n",
            "[1,  6000] loss: 1.451\n",
            "[1,  8000] loss: 1.356\n",
            "[1, 10000] loss: 1.313\n",
            "[1, 12000] loss: 1.265\n",
            "[2,  2000] loss: 1.120\n",
            "[2,  4000] loss: 1.127\n",
            "[2,  6000] loss: 1.099\n",
            "[2,  8000] loss: 1.052\n",
            "[2, 10000] loss: 1.056\n",
            "[2, 12000] loss: 0.998\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 64.79\n",
            "[1,  2000] loss: 1.956\n",
            "[1,  4000] loss: 1.646\n",
            "[1,  6000] loss: 1.523\n",
            "[1,  8000] loss: 1.494\n",
            "[1, 10000] loss: 1.406\n",
            "[1, 12000] loss: 1.378\n",
            "[2,  2000] loss: 1.296\n",
            "[2,  4000] loss: 1.287\n",
            "[2,  6000] loss: 1.256\n",
            "[2,  8000] loss: 1.243\n",
            "[2, 10000] loss: 1.217\n",
            "[2, 12000] loss: 1.196\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 56.69\n",
            " Epoch: 0, Avg Return per Epoch: 61.393[1,  2000] loss: 2.043\n",
            "[1,  4000] loss: 1.662\n",
            "[1,  6000] loss: 1.553\n",
            "[1,  8000] loss: 1.506\n",
            "[1, 10000] loss: 1.458\n",
            "[1, 12000] loss: 1.415\n",
            "[2,  2000] loss: 1.345\n",
            "[2,  4000] loss: 1.345\n",
            "[2,  6000] loss: 1.306\n",
            "[2,  8000] loss: 1.295\n",
            "[2, 10000] loss: 1.307\n",
            "[2, 12000] loss: 1.266\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 55.55\n",
            "[1,  2000] loss: 1.947\n",
            "[1,  4000] loss: 1.609\n",
            "[1,  6000] loss: 1.497\n",
            "[1,  8000] loss: 1.433\n",
            "[1, 10000] loss: 1.373\n",
            "[1, 12000] loss: 1.348\n",
            "[2,  2000] loss: 1.259\n",
            "[2,  4000] loss: 1.193\n",
            "[2,  6000] loss: 1.212\n",
            "[2,  8000] loss: 1.185\n",
            "[2, 10000] loss: 1.167\n",
            "[2, 12000] loss: 1.174\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 59.99\n",
            "[1,  2000] loss: 1.940\n",
            "[1,  4000] loss: 1.608\n",
            "[1,  6000] loss: 1.547\n",
            "[1,  8000] loss: 1.458\n",
            "[1, 10000] loss: 1.427\n",
            "[1, 12000] loss: 1.385\n",
            "[2,  2000] loss: 1.318\n",
            "[2,  4000] loss: 1.313\n",
            "[2,  6000] loss: 1.286\n",
            "[2,  8000] loss: 1.277\n",
            "[2, 10000] loss: 1.260\n",
            "[2, 12000] loss: 1.243\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 56.46\n",
            " Epoch: 1, Avg Return per Epoch: 59.363[1,  2000] loss: 1.933\n",
            "[1,  4000] loss: 1.591\n",
            "[1,  6000] loss: 1.426\n",
            "[1,  8000] loss: 1.364\n",
            "[1, 10000] loss: 1.275\n",
            "[1, 12000] loss: 1.214\n",
            "[2,  2000] loss: 1.143\n",
            "[2,  4000] loss: 1.087\n",
            "[2,  6000] loss: 1.092\n",
            "[2,  8000] loss: 1.061\n",
            "[2, 10000] loss: 1.050\n",
            "[2, 12000] loss: 1.050\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 63.2\n",
            "[1,  2000] loss: 2.013\n",
            "[1,  4000] loss: 1.668\n",
            "[1,  6000] loss: 1.563\n",
            "[1,  8000] loss: 1.480\n",
            "[1, 10000] loss: 1.457\n",
            "[1, 12000] loss: 1.386\n",
            "[2,  2000] loss: 1.352\n",
            "[2,  4000] loss: 1.312\n",
            "[2,  6000] loss: 1.282\n",
            "[2,  8000] loss: 1.272\n",
            "[2, 10000] loss: 1.231\n",
            "[2, 12000] loss: 1.243\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 56.74\n",
            "[1,  2000] loss: 1.997\n",
            "[1,  4000] loss: 1.638\n",
            "[1,  6000] loss: 1.492\n",
            "[1,  8000] loss: 1.439\n",
            "[1, 10000] loss: 1.423\n",
            "[1, 12000] loss: 1.362\n",
            "[2,  2000] loss: 1.274\n",
            "[2,  4000] loss: 1.254\n",
            "[2,  6000] loss: 1.236\n",
            "[2,  8000] loss: 1.237\n",
            "[2, 10000] loss: 1.199\n",
            "[2, 12000] loss: 1.194\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 57.65\n",
            " Epoch: 2, Avg Return per Epoch: 59.308[1,  2000] loss: 1.979\n",
            "[1,  4000] loss: 1.660\n",
            "[1,  6000] loss: 1.519\n",
            "[1,  8000] loss: 1.428\n",
            "[1, 10000] loss: 1.354\n",
            "[1, 12000] loss: 1.288\n",
            "[2,  2000] loss: 1.203\n",
            "[2,  4000] loss: 1.174\n",
            "[2,  6000] loss: 1.160\n",
            "[2,  8000] loss: 1.110\n",
            "[2, 10000] loss: 1.128\n",
            "[2, 12000] loss: 1.090\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 62.08\n",
            "[1,  2000] loss: 2.150\n",
            "[1,  4000] loss: 1.777\n",
            "[1,  6000] loss: 1.648\n",
            "[1,  8000] loss: 1.582\n",
            "[1, 10000] loss: 1.554\n",
            "[1, 12000] loss: 1.513\n",
            "[2,  2000] loss: 1.459\n",
            "[2,  4000] loss: 1.444\n",
            "[2,  6000] loss: 1.438\n",
            "[2,  8000] loss: 1.408\n",
            "[2, 10000] loss: 1.390\n",
            "[2, 12000] loss: 1.381\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 49.01\n",
            "[1,  2000] loss: 1.971\n",
            "[1,  4000] loss: 1.628\n",
            "[1,  6000] loss: 1.475\n",
            "[1,  8000] loss: 1.392\n",
            "[1, 10000] loss: 1.322\n",
            "[1, 12000] loss: 1.285\n",
            "[2,  2000] loss: 1.183\n",
            "[2,  4000] loss: 1.158\n",
            "[2,  6000] loss: 1.135\n",
            "[2,  8000] loss: 1.105\n",
            "[2, 10000] loss: 1.094\n",
            "[2, 12000] loss: 1.046\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 60.27\n",
            " Epoch: 3, Avg Return per Epoch: 58.761[1,  2000] loss: 1.996\n",
            "[1,  4000] loss: 1.621\n",
            "[1,  6000] loss: 1.467\n",
            "[1,  8000] loss: 1.373\n",
            "[1, 10000] loss: 1.316\n",
            "[1, 12000] loss: 1.278\n",
            "[2,  2000] loss: 1.149\n",
            "[2,  4000] loss: 1.146\n",
            "[2,  6000] loss: 1.118\n",
            "[2,  8000] loss: 1.086\n",
            "[2, 10000] loss: 1.073\n",
            "[2, 12000] loss: 1.049\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 61.75\n",
            "[1,  2000] loss: 1.963\n",
            "[1,  4000] loss: 1.660\n",
            "[1,  6000] loss: 1.503\n",
            "[1,  8000] loss: 1.447\n",
            "[1, 10000] loss: 1.380\n",
            "[1, 12000] loss: 1.352\n",
            "[2,  2000] loss: 1.259\n",
            "[2,  4000] loss: 1.232\n",
            "[2,  6000] loss: 1.215\n",
            "[2,  8000] loss: 1.185\n",
            "[2, 10000] loss: 1.181\n",
            "[2, 12000] loss: 1.174\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 60.09\n",
            "[1,  2000] loss: 1.930\n",
            "[1,  4000] loss: 1.564\n",
            "[1,  6000] loss: 1.451\n",
            "[1,  8000] loss: 1.368\n",
            "[1, 10000] loss: 1.309\n",
            "[1, 12000] loss: 1.268\n",
            "[2,  2000] loss: 1.166\n",
            "[2,  4000] loss: 1.131\n",
            "[2,  6000] loss: 1.107\n",
            "[2,  8000] loss: 1.070\n",
            "[2, 10000] loss: 1.050\n",
            "[2, 12000] loss: 1.041\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 62.79\n",
            " Epoch: 4, Avg Return per Epoch: 59.317"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "8LIp7bwBt1Ug",
        "outputId": "3442f1b1-3814-4343-a4fb-d5f0c0e2b8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0994fe58f8f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'actions' is not defined"
          ]
        }
      ]
    }
  ]
}